<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>æ³•å‘é‡ä¼°è®¡çš„ä¸€äº›å¸¸ç”¨æ–¹æ³•</title>
    <link href="/2022/02/03/Normal-estimation/"/>
    <url>/2022/02/03/Normal-estimation/</url>
    
    <content type="html"><![CDATA[<h2 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h2><p>è¿™ç¯‡åšå®¢ä¸»è¦ä»‹ç»æ³•å‘é‡ä¼°è®¡ï¼ˆNormal estimationï¼‰çš„ä¸€äº›å¸¸ç”¨æ–¹æ³•ã€‚</p><p>å¯¹äºä¸‰ç»´æ·±åº¦æ•°æ®ï¼ˆRange dataï¼‰ç›®å‰å·²ç»å­˜åœ¨è®¸å¤šæ³•å‘é‡ä¼°è®¡æ–¹æ³•ï¼Œè¿™é‡Œé¦–å…ˆä»‹ç»ä¸€ç§æœ€ç®€å•çš„ä¼°è®¡æ–¹æ³•ã€‚</p><h2 id="A-method-based-on-the-first-order-3D-plane-fitting"><a href="#A-method-based-on-the-first-order-3D-plane-fitting" class="headerlink" title="A method based on the first order 3D plane fitting"></a>A method based on the first order 3D plane fitting</h2><p>è¯¥æ–¹æ³•ç”± Jens Berkmann and Terry Caelli æå‡º<sup> <a href="#ref1">[1]</a> </sup>ã€‚æˆ‘ä»¬å¯ä»¥å°†è¡¨é¢ç‚¹çš„æ³•å‘é‡ä¼°è®¡é—®é¢˜è½¬åŒ–ä¸ºè¡¨é¢ç‚¹çš„åˆ‡å¹³é¢ä¼°è®¡ï¼Œç„¶åé€šè¿‡åˆ‡å¹³é¢çš„æ³•å‘é‡æ¥ä¼°è®¡è¯¥ç‚¹å¤„çš„æ³•å‘é‡ã€‚å…·ä½“æ–¹æ³•å¦‚ä¸‹ï¼š</p><p>é€šè¿‡Liang and Todhunter çš„ç ”ç©¶ç»“æœ <sup><a href="#ref2">[2]</a></sup> ï¼Œè‹¥æœ‰å±€éƒ¨è¡¨é¢å¤„ç‚¹$P_q$ï¼Œå…¶é¢†åŸŸç‚¹é›†ä¸º$N_p$ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰å±€éƒ¨è¡¨é¢å¤„ç‚¹$P_q$çš„åæ–¹å·®çŸ©é˜µ$C_I$ï¼š<br>$$<br>C_I = \frac{1}{n} \sum_{i=1}^{n}(P_i - P_m)\cdot (P_i - P_m)^{T}<br>$$<br>ä¸Šå¼ä¸­ï¼Œ</p><p>$P_i \in N_p$ï¼Œ$P_i=(x_i,y_i,z_i)^T$ä¸ºå…¶ä¸­ç¬¬$i$ä¸ªç‚¹çš„ä½ç½®ï¼›</p><p>$n$ä¸ºé¢†åŸŸä¸­ç‚¹çš„ä¸ªæ•°ï¼›</p><p>$P_m$æ˜¯é‚»åŸŸç‚¹é›†çš„ä¸­å¿ƒç‚¹ï¼Œå¯ä»¥é€šè¿‡å…¬å¼$P_m = \frac{1}{n} \sum_{i=1}^{n} P_i$è®¡ç®—å¾—åˆ°ï¼›</p><p>é€šè¿‡ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„å®šä¹‰ï¼š$C_I \cdot \vec{v}_j = \lambda_j \vec{v}_j,j \in {0,1,2 }$ï¼Œå¯ä»¥è®¡ç®—å¾—åˆ°å¯¹åº”ä¸‰ä¸ªæ­£äº¤çš„ç‰¹å¾å‘é‡ã€‚å¦‚æœæœ‰$0 \leq \lambda_0 \leq \lambda_1 \leq \lambda_2 $ï¼Œåˆ™ $\lambda_0$ å¯¹åº”çš„ç‰¹å¾å‘é‡ $\vec{v}_0$ ä¸ºè¯¥ç‚¹å¯¹åº”æ³•å‘é‡ $\vec{n}$ æˆ– $- \vec{n}$ çš„ä¼°è®¡å€¼ã€‚</p><p>æ­¤å¤–ï¼Œå¯ä»¥å¯¹åº”å¾—åˆ°è¯¥ç‚¹çš„æ›²ç‡å€¼ $\sigma$ ï¼š<br>$$<br>\sigma = \frac{\lambda_0}{\lambda_0 + \lambda_1 + \lambda_2}<br>$$</p><h2 id="å…¶ä»–æ–¹æ³•"><a href="#å…¶ä»–æ–¹æ³•" class="headerlink" title="å…¶ä»–æ–¹æ³•"></a>å…¶ä»–æ–¹æ³•</h2><p>ä¹‹åè¿˜ä¼šè¡¥å……å…¶ä»–æ–¹æ³•ã€‚</p><h2 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h2><p><a name="ref1"><font color="blue">[1]</font></a> <a href="https://ieeexplore.ieee.org/document/334391">Jens Berkmann and Terry Caelli. Computation of Surface Geometry and Segmentation Using Covariance Techniques. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 16(11):1114â€“1116, November 1994. </a></p><p><a name="ref2"><font color="blue">[2]</font></a> <a href="https://www.sciencedirect.com/science/article/abs/pii/0734189X9090124E">P. Liang and J. S. Todhunter, â€œRepresentation and recognition of surface shapes in range images,â€Computer Vision, Graphics and Image Processing, vol. 52, no. 10, pp. 78-109, 1990</a>  </p>]]></content>
    
    
    <categories>
      
      <category>Linear Fitting</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linear Fitting</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3-Point cloud file format</title>
    <link href="/2022/01/23/3-point-cloud/"/>
    <url>/2022/01/23/3-point-cloud/</url>
    
    <content type="html"><![CDATA[<h2 id="Point-cloud-file-format"><a href="#Point-cloud-file-format" class="headerlink" title="Point cloud file format"></a>Point cloud file format</h2><p>This chapter mainly introduces the different formats of point cloud storage. Different file formats have different application scenarios and processing methods. Here are some formats:</p><p><img src="/2022/01/23/3-point-cloud/point_cloud_file_format.png" alt="Point cloud file formats"></p><ul><li><p><b><i>PCD :</i></b>  <code>Point Cloud Data, PCL (Point Cloud Library) officially designated file, which is used to store the specific information of the point cloud (PCL (Point Cloud Library) is a C++ library for processing point clouds.</code></p></li><li><p><b><i>TXT :</i></b>  <code>It is used to store the point information of the point cloud, and the operation is simple, consistent with the txt file processing method we usually process data</code></p></li><li><p><b><i>VTK :</i></b>  <code>In addition to storing point information, it also stores the topological relationship between points</code></p></li><li><p><b><i>PLY :</i></b>  <code>Three-dimensional mesh model data format, only used to describe a polygon model object, that is, a mesh structure model</code></p></li><li><p><b><i>OFF :</i></b>  <code>It is used to save the polygon information of the geometry</code></p></li><li><p><b><i>OBJ :</i></b>  <code>The geometrically defined file format mainly supports polygonal models, that is, mesh structure models</code></p></li><li><p><b><i>STL :</i></b>  <code>It is used to store point information and topological information, representing a closed surface or volume</code></p></li><li><p><b><i>BIN :</i></b>  <code>Different from the above seven kinds of files, a file with a suffix of .bin just wants to show that it is in binary format. But it does not mean that it is necessarily related to a certain application, and a bin file may not be point cloud data</code></p></li></ul><p>Supplementary reading about these formats: <a href="https://github.com/oxon-612/PointCloud_Tutorial/blob/main/Chapter3/Chapter3_en/Chapter3%20Point%20cloud%20file%20format.md">PointCloud_Tutorial Chapter 3</a></p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://github.com/oxon-612/PointCloud_Tutorial/tree/main/Chapter3/Chapter3_en">PointCloud_Tutorial</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Point Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Point Cloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2-Point Cloud Software</title>
    <link href="/2022/01/17/2-point-cloud/"/>
    <url>/2022/01/17/2-point-cloud/</url>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p><b>Irrelevant points</b></p><p>The point cloud is a set of massive points, which may contain some messy irrelevant points. These points may affect the efficiency in the processing of point cloud, and even influence the accuracy of algorithms. As shown below, it is the point cloud data of a bridge scene. If we are only interested in the bridge body, then the trees and vehicles in the red frame are irrelevant points.</p><p><img src="/2022/01/17/2-point-cloud/irrelevant_points.png" alt="Irrelevant Points"></p></li><li><p><b>Pre-pocessing</b></p><p>The original point cloud is too large and generally not directly used for subsequent processing. Usually, we will first pre-process the data. Pre-processing includes <b>cropping, cutting, cleaning, and downsampling</b> the point cloud, etc.</p><p><img src="/2022/01/17/2-point-cloud/pre-processing.png" alt="Pre-processing"></p></li></ul><p>How to realize these operations?</p><p>One of the commonly used methods is to perform rapid and appropriate processing through existing commercial or free software. This Blog  mainly introduces two commonly used free open source software: <i><b>CloudCompare &amp; MeshLab</b></i></p><h2 id="CloudCompare"><a href="#CloudCompare" class="headerlink" title="CloudCompare"></a>CloudCompare</h2><p>Here are a few small tools:</p><ul><li><p>CloudCompare source code. After we are very familiar with point cloud processing technology, we can write source code here:</p><p>ğŸ‘‰ <a href="https://github.com/cloudcompare/cloudcompare">https://github.com/cloudcompare/cloudcompare</a></p></li><li><p>The following link intuitively introduces the basic operations of CloudCompare in YouTube:</p><p>ğŸ‘‰ <a href="https://www.youtube.com/playlist?list=PLBNUxsUA00UAT63O0d95pByrCjtqlXN4">https://www.youtube.com/playlist?list=PLBNUxsUA00UAT63O0d95pByrCjtqlXN4</a>_</p></li></ul><p>You can find more detailed operations in <a href="https://github.com/oxon-612/PointCloud_Tutorial/blob/main/Chapter2/Chapter2_zh/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E7%82%B9%E4%BA%91%E8%BD%AF%E4%BB%B6.md">PointCloud_Tutorial Chapter2</a>.</p><h2 id="MeshLab"><a href="#MeshLab" class="headerlink" title="MeshLab"></a>MeshLab</h2><p>Here are a few small tools to assist us in learning:</p><ul><li><p>MeshLab source code:</p><p>ğŸ‘‰ <a href="https://github.com/cnr-isti-vclab/meshlab/releases">https://github.com/cnr-isti-vclab/meshlab/releases</a></p></li><li><p>The following link intuitively introduces the basic operations of MeshLab in YouTube:</p><p>ğŸ‘‰ Basicsï¼š<a href="https://www.youtube.com/playlist?list=PL8B1E816EAE236B4D">https://www.youtube.com/playlist?list=PL8B1E816EAE236B4D</a></p><p>ğŸ‘‰ Featuresï¼š<a href="https://www.youtube.com/playlist?list=PL60mCsep96JcJz_SIfXblsVmI1TYMsQJc">https://www.youtube.com/playlist?list=PL60mCsep96JcJz_SIfXblsVmI1TYMsQJc</a></p><p>ğŸ‘‰ 3D Scanning pipelineï¼š<a href="https://www.youtube.com/playlist?list=PL53FAE3EB5734126E">https://www.youtube.com/playlist?list=PL53FAE3EB5734126E</a></p><p>ğŸ‘‰ Cleaningï¼š<a href="https://www.youtube.com/playlist?list=PLBBF41579E4B65566">https://www.youtube.com/playlist?list=PLBBF41579E4B65566</a></p></li><li><p>MeshLab tutorial:</p><p>ğŸ‘‰ <a href="http://www.heritagedoc.pt/doc/Meshlab_Tutorial_iitd.pdf">http://www.heritagedoc.pt/doc/Meshlab_Tutorial_iitd.pdf</a></p></li></ul><h2 id="Related-concepts"><a href="#Related-concepts" class="headerlink" title="Related concepts"></a>Related concepts</h2><h3 id="Bounding-Box"><a href="#Bounding-Box" class="headerlink" title="Bounding Box"></a>Bounding Box</h3><p>The point cloud may have a complicated shape and structure, but no matter how complex the point cloud itself is, its Bounding Box is always a regular and straightforward cuboid. It can help us quickly get the range of the point cloud and facilitate subsequent operations using this range. </p><p>It should be noted that the Bounding Box in CloudComapre is <b>Axis-Aligned Bounding Box (AABB)</b>. In addition to AABB in CloudCompare, there is also a directed Bounding Box, which is called <b>Oriented Bounding Box (OBB)</b>. AABB and OBB are both Bounding Box. What is the difference between them?</p><ul><li><b>Oriented Bounding Box</b> is always aligned with the  principal component direction of the point cloud (PCA can be used to  calculate the principal component direction);</li><li><b>Axis-Aligned Bounding Box</b> is always aligned with the coordinate axis;</li></ul><p><img src="/2022/01/17/2-point-cloud/two_bounding_box.png" alt="Two different bounding boxes"></p><p>Through the above introduction, we can see that OBB is more accurate than AABB to describe the range of point cloud. AABB will frame much invalid space, which will have a particular impact on efficiency in actual algorithm application. When we need a piece of more accurate range information, we generally choose to calculate OBB.</p><h3 id="Cutting"><a href="#Cutting" class="headerlink" title="Cutting"></a>Cutting</h3><h4 id="ROI"><a href="#ROI" class="headerlink" title="ROI"></a>ROI</h4><p>Computer Vision is actually to let the computer automatically understand a picture or a scene. </p><p>Putting it in the background of the point cloud means that the computer can understand the point cloud like a human. For the point cloud of a car, people can immediately recognize that it is a car based on their knowledge, and can point out that it has wheels and so on. According to our needs, we can find out <b>the Region of Interest (ROI)</b>, that is, extract a specific point cloud region. ROI varies from situation to situation. It can be a wheel of a car point cloud, a spot on the hood of a car, or some unrelated points next to the vehicle.</p><h4 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h4><p>According to semantic segmentation, this idea is also used when we want to segment the point cloud into small individuals. Point cloud processing is essentially the same as the processing of 2D images. Many of the problems of 2D are the same as those of 3D, but the specific processing methods are different. 2D images also have semantic segmentation, aiming to understand the image and divide the image into semantic regions. Such as, given a photo, as shown below, the machine should be able to label cars, buildings, trees, and other objects in different colors after judging:</p><p><img src="/2022/01/17/2-point-cloud/2D_senmantic_seg.jpg" alt="2D semantic segmentation"></p><p>The point cloud is a crucial way of expressing 3-dimensional objects also to realize semantic segmentation. The figure below is a schematic diagram of the semantic segmentation of a 3D point cloud. The bridge body is divided into different parts (represented by different colors).</p><p><img src="/2022/01/17/2-point-cloud/pointcloud_semantic_seg.png" alt="Point cloud semantic segmentation"></p><p>How to use CloudCompare for point cloud cutting? You can find details in <a href="https://github.com/oxon-612/PointCloud_Tutorial/blob/main/Chapter2/Chapter2_en/Chapter2%20Point%20Cloud%20Software.md">PointCloud_Tutorial Chapter2</a></p><h3 id="Downsampling"><a href="#Downsampling" class="headerlink" title="Downsampling"></a>Downsampling</h3><p>Downsampling is a critical step in the process of the processing point cloud. Sometimes the point cloud file we get is huge. For example, a real bridge point cloud will have 2G to 3G. If we use this file to perform experiments or develop algorithms, it will significantly reduce efficiency. Therefore, we can choose to downsample to reduce the number of points in the point cloud and facilitate processing.</p><p>Downsampling is essentially a process from more to less, and the final point cloud is a subset of the original point cloud. The coordinates and colors of the points obtained by downsampling still correspond to their information in the original point cloud, as shown below:</p><p><img src="/2022/01/17/2-point-cloud/downsampling.png" alt="Downsampling"></p><p>CloudCompare provides three downsamping methods: <b>Random, Space, Octree</b></p><ul><li><p>Random</p><p><b>Advantage:</b> Random downsampling principle is simple. Just set the number of reserved points to select points as the left downsampling result point cloud randomly;</p><p><b>Disadvantage:</b> Random downsampling has no focus. Randomly select the entire point cloud so that important information may be lost.</p></li><li><p>Space</p><p>Space downsampling is based on distance.</p><p><b>Use active SF</b>:</p><p>Space also has an optional box Use active SF. SF is Scalar Field. There are many Scalar Fields in the point cloud, such as curvature, confidence, etc. We can set the space distance according to the value of these Scalar Fields instead of setting the same distance for the entire point cloud.</p><p>The most intuitive example is to set different distance thresholds according to different curvatures. Curvature, generally speaking, is the degree of bending. Some point cloud surface textures are involved, such as sculptures or other objects with uneven surfaces, and the curvature of these areas will be larger than other relatively flat surfaces. The area with large curvature means that it contains richer geometric information. The flat surfaces can be described by a few points or only three points (such as a plane). In contrast, the more complex and rugged surfaces need more points to describe their geometric properties. </p><p>In other words, the curvature can be used as an indicator to distinguish the geometric complexity of a surface. The smaller the curvature, the flatter the surface represented by the point cloud, and the lower the geometric complexity. On the contrary, the greater the curvature, the greater the degree of change of the surface represented by the point cloud, the more rugged, and the higher the geometric complexity. </p></li><li><p>Octree</p><p>Octree corresponds to â€œbinary treeâ€:</p><p>Each node of the binary tree has up to 2 child nodes, and each node of the octree has up to 8 child nodes. The process of a continuous division of octree is essentially the process of constant equal division of small cubes, as shown below. These small cubes are also called â€œvoxels.â€</p><p><img src="/2022/01/17/2-point-cloud/Octree.png" alt="Octree"></p><p>Processing steps:</p><p>Step1: Use a small cube to frame the original point cloud;</p><p>Step2: Set the Octree level. Here level = 1. This setup divides the big cube into eight small cubes. If there is no point in a small cube, the cube is deleted. </p><p>Step3: core step of Octree. We keep the point which is the most close to the Central point of each voxel. And one voxel is allowed to keep only one point. </p><p><img src="/2022/01/17/2-point-cloud/octree_processing.png" alt="Octree processing"></p></li></ul><h3 id="Resampling"><a href="#Resampling" class="headerlink" title="Resampling"></a>Resampling</h3><p>In CloudCompare, Octree can be used for resampling. The idea of Octree downsampling and Octree resampling is the same. The difference is:</p><p>Octree resampling keeps the center of gravity of all points in each small cube after division, instead of the closest point to the center of the cube in each cube.</p><blockquote><p>Notice:</p><p>Octree resampling is to create a new point cloud that is different from the original one, so it may not retain the critical features of the original point cloud, such as color, normal, curvature, etc. If you want to keep this information, you can consider Octree downsampling.</p></blockquote><h3 id="Calculate-distance"><a href="#Calculate-distance" class="headerlink" title="Calculate  distance"></a>Calculate  distance</h3><h4 id="Cloud-to-Cloud-Distance"><a href="#Cloud-to-Cloud-Distance" class="headerlink" title="Cloud-to-Cloud Distance"></a>Cloud-to-Cloud Distance</h4><p>Cloud-to-Cloud distance is to calculate the Euclidean distance between each point and the nearest point in another point cloud, that is, the nearest neighbor distance.</p><p>When we calculate the distance, we look for points in the Reference cloud closest to each point in the Compared cloud, calculate the distance between every two points, and then calculate the average of all distances to get the final Cloud -to-Cloud Distance.</p><p><b>nearest neighbor distance</b> learning link: <a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search">https://en.wikipedia.org/wiki/Nearest_neighbor_search</a></p><p><img src="/2022/01/17/2-point-cloud/cloud-to-cloud_distance.png" alt="Cloud-to-Cloud Distance"></p><h4 id="Cloud-to-Mesh-Distance"><a href="#Cloud-to-Mesh-Distance" class="headerlink" title="Cloud-to-Mesh Distance"></a>Cloud-to-Mesh Distance</h4><p>Cloud-to-Mesh Distance refers to the distance between a point cloud and a mesh. The calculation principle is to calculate the distance between each point and the nearest triangle in the mesh.</p><p><img src="/2022/01/17/2-point-cloud/cloud-to-mesh_distance.png" alt="Cloud-to-Mesh Distance"></p><h3 id="Compute-normal"><a href="#Compute-normal" class="headerlink" title="Compute normal"></a>Compute normal</h3><p>Normal can be applied in scenes such as point cloud rendering. Besides, computing normal is also the basis of algorithms such as triangulation. </p><p><img src="/2022/01/17/2-point-cloud/normal.png" alt="Normal"></p><h3 id="Registration"><a href="#Registration" class="headerlink" title="Registration"></a>Registration</h3><p>Registration is an essential algorithm for the processing point cloud. It is to register or splice multiple point clouds of different local coordinate systems by finding the overlap with each other so that they appear in the same coordinate system. As shown in below, (a) and (b) are respectively the point cloud in the two local coordinate systems of the building. After registration, we get (c), that is, (a) and (b) are joined together to form a point cloud of a complete building in a coordinate system:</p><p><img src="/2022/01/17/2-point-cloud/registration.png" alt="Registration"></p><p>The well-known algorithm for registering point clouds is Iterative Closest Point (ICP)</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://github.com/oxon-612/PointCloud_Tutorial">PointCloud_Tutorial</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Point Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Point Cloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1-Basic knowledge of point cloud</title>
    <link href="/2022/01/17/1-point-cloud-fundation/"/>
    <url>/2022/01/17/1-point-cloud-fundation/</url>
    
    <content type="html"><![CDATA[<h3 id="What-is-point-cloud"><a href="#What-is-point-cloud" class="headerlink" title="What is point cloud?"></a>What is point cloud?</h3><blockquote><p>Concept: </p><p>Point cloud is a massive collection of points expressing target spatial distribution and target surface characteristics in the same spatial coordinate system, which is the â€œSampling of object surface â€œ.</p></blockquote><ul><li><p><b>What does the same spatial coordinate system mean?  Why the same? </b></p><p>The same spatial coordinate system represents point cloud is the data in 3-dimensional space;</p><p>â€œThe sameâ€ means that all points in the point cloud are in the same coordinate system, instead of belonging to multiple coordinate systems, as shown below:</p></li></ul><p><img src="/2022/01/17/1-point-cloud-fundation/The_same_coordinate_system.png" alt="The same coordinate system"></p><p>The concept of point cloud not only emphasizes that the point cloud is a â€œcollection of pointsâ€, more importantly, the point cloud is a sampling of object surface â€”â€” Sampling refers to the process of getting a sample of individuals from the population. Scanning is to sample the object surface, and the point cloud is sample points on the object surface.</p><h3 id="Point-Cloud-View"><a href="#Point-Cloud-View" class="headerlink" title="Point Cloud View"></a>Point Cloud View</h3><p>The following figure shows several point cloud views: rabbit.pcd, bridge.bin, chair.pcd, airplane.pcd, bottle.pcd.</p><p><img src="/2022/01/17/1-point-cloud-fundation/point_cloud_view.png" alt="Point cloud View"></p><h3 id="Features-of-point-cloud"><a href="#Features-of-point-cloud" class="headerlink" title="Features of point cloud"></a>Features of point cloud</h3><ul><li>Translation and rotation in space can not change characteristics of point cloud itself, which can be reflected in the point cloud algorithm many times. </li><li>What we focus on is the spatial coordinate or color and other information of each point. Thus, the point size and other irrelevant factors do not influence our research. It generally has an impact on the view.</li></ul><p><img src="/2022/01/17/1-point-cloud-fundation/point_size.png" alt="Point Size"></p><ul><li>The point cloud collection is non-intrusive. That is, there is no impact or interference on the scene or the building when we use a laser  scanner to scan them.</li></ul><h3 id="How-to-get-point-cloud"><a href="#How-to-get-point-cloud" class="headerlink" title="How to get point cloud?"></a>How to get point cloud?</h3><h4 id="Real-point-cloud"><a href="#Real-point-cloud" class="headerlink" title="Real point cloud"></a><b>Real point cloud</b></h4><p>The real point cloud is obtained from the objects in the real scene through some instruments. Such as 3D laser scanner.</p><h4 id="Virtual-point-cloud"><a href="#Virtual-point-cloud" class="headerlink" title="Virtual point cloud"></a><b>Virtual point cloud</b></h4><p>Open datasets:</p><p>There are also some public point cloud datasets available for download:</p><ul><li><p><i>The Stanford 3D Scanning Repository</i></p><p>linkï¼š <a href="http://www.cc.gatech.edu/projects/large_models/">http://www.cc.gatech.edu/projects/large_models/</a></p><p>When we are new to the point cloud, we can download many point cloud datasets from this website. Because the point cloud data volume of this website is small, the operation is convenient. Among them, â€œbunnyâ€ (also known as Stanford Bunny) is often used in significant point cloud algorithm examples.</p><p><img src="/2022/01/17/1-point-cloud-fundation/stanford_3d.png" alt="The Stanford 3D Scanning Repository"></p></li><li><p><i>Sydney Urban Objects Dataset</i></p><p>linkï¼š<a href="http://www.acfr.usyd.edu.au/papers/SydneyUrbanObjectsDataset.shtml">http://www.acfr.usyd.edu.au/papers/SydneyUrbanObjectsDataset.shtml</a></p><p>This dataset was acquired using LiDAR in the CBD area of Sydney, Australia, and covers a variety of common urban road objects. Such as all kinds of vehicles on the road, pedestrians, roadside trees, etc., include a total of 631 individual scanned objects. They are mainly used to test matching and classification algorithms.</p><p><img src="/2022/01/17/1-point-cloud-fundation/arranged.png" alt="Sydney Urban Objects Dataset"></p></li><li><p><i>ASL Datasets Repository</i></p><p>linkï¼š<a href="https://projects.asl.ethz.ch/datasets/doku.php?id=home">https://projects.asl.ethz.ch/datasets/doku.php?id=home</a></p><p>This dataset contains many point cloud data, which can be used for target detection and matching, point cloud registration, etc.</p></li><li><p><i>The KITTI Vision Benchmark Suite</i></p><p>linkï¼š<a href="http://www.cvlibs.net/datasets/kitti/">http://www.cvlibs.net/datasets/kitti/</a></p><p>The KITTI Vision Benchmark Suite comes from a project of the Karlsruhe Institute of Technology in Germany. It contains a large number of urban environment point cloud datasets (KITTI) collected by KITâ€™s UGV platform. This dataset not only includes radar, image, GPS, and INS data but also has manually labeled segmentation and tracking results, which can be used to objectively evaluate the effect and performance of large-scale 3D modeling and classification</p><p><img src="/2022/01/17/1-point-cloud-fundation/KITTI.png" alt="The KITTI Vision Benchmark Suite"></p></li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol><li><a href="https://github.com/oxon-612/PointCloud_Tutorial">PointCloud_Tutorial</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Point Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Point Cloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>The first day at SleepTown</title>
    <link href="/2022/01/15/The-first-day-at-SleepTown/"/>
    <url>/2022/01/15/The-first-day-at-SleepTown/</url>
    
    <content type="html"><![CDATA[<p>Welcome to SleepTown! Iâ€™m the mayor, the first and maybe the only habitant of this town. </p><p>You guys can call me SleepyKIKI. And you must be curious about what life like in SleepTown. You can find answers below.</p><h2 id="Quick-Start-in-SleepTwon"><a href="#Quick-Start-in-SleepTwon" class="headerlink" title="Quick Start in SleepTwon"></a>Quick Start in SleepTwon</h2><h3 id="Why-to-create-this-Town-Blog"><a href="#Why-to-create-this-Town-Blog" class="headerlink" title="Why to create this Town(Blog)?"></a>Why to create this Town(Blog)?</h3><p>At first to record my college graduation project and some tech knowledge. But I also hope to record my sweet personal life. This is the space with happy moments and fragrant smell. </p><p>Hope you can enjoy the moments in SleepTown. If you feel tired, just get in and take a nap!</p><p><img src="/2022/01/15/The-first-day-at-SleepTown/Holiday_beach.png" alt="Holiday"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Daily life</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/01/14/hello-world/"/>
    <url>/2022/01/14/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></div></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo server<br></code></pre></div></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo generate<br></code></pre></div></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></div></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
