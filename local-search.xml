<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>2-Point Cloud Software</title>
    <link href="/2022/01/17/2-point-cloud/"/>
    <url>/2022/01/17/2-point-cloud/</url>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p><b>Irrelevant points</b></p><p>The point cloud is a set of massive points, which may contain some messy irrelevant points. These points may affect the efficiency in the processing of point cloud, and even influence the accuracy of algorithms. As shown below, it is the point cloud data of a bridge scene. If we are only interested in the bridge body, then the trees and vehicles in the red frame are irrelevant points.</p><p><img src="/2022/01/17/2-point-cloud/irrelevant_points.png" alt="Irrelevant Points"></p></li><li><p><b>Pre-pocessing</b></p><p>The original point cloud is too large and generally not directly used for subsequent processing. Usually, we will first pre-process the data. Pre-processing includes <b>cropping, cutting, cleaning, and downsampling</b> the point cloud, etc.</p><p><img src="/2022/01/17/2-point-cloud/pre-processing.png" alt="Pre-processing"></p></li></ul><p>How to realize these operations?</p><p>One of the commonly used methods is to perform rapid and appropriate processing through existing commercial or free software. This Blog  mainly introduces two commonly used free open source software: <i><b>CloudCompare &amp; MeshLab</b></i></p><h2 id="CloudCompare"><a href="#CloudCompare" class="headerlink" title="CloudCompare"></a>CloudCompare</h2><p>Here are a few small tools:</p><ul><li><p>CloudCompare source code. After we are very familiar with point cloud processing technology, we can write source code here:</p><p>üëâ <a href="https://github.com/cloudcompare/cloudcompare">https://github.com/cloudcompare/cloudcompare</a></p></li><li><p>The following link intuitively introduces the basic operations of CloudCompare in YouTube:</p><p>üëâ <a href="https://www.youtube.com/playlist?list=PLBNUxsUA00UAT63O0d95pByrCjtqlXN4">https://www.youtube.com/playlist?list=PLBNUxsUA00UAT63O0d95pByrCjtqlXN4</a>_</p></li></ul><p>You can find more detailed operations in <a href="https://github.com/oxon-612/PointCloud_Tutorial/blob/main/Chapter2/Chapter2_zh/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E7%82%B9%E4%BA%91%E8%BD%AF%E4%BB%B6.md">PointCloud_Tutorial Chapter2</a>.</p><h3 id="Bounding-Box"><a href="#Bounding-Box" class="headerlink" title="Bounding Box"></a>Bounding Box</h3><p>The point cloud may have a complicated shape and structure, but no matter how complex the point cloud itself is, its Bounding Box is always a regular and straightforward cuboid. It can help us quickly get the range of the point cloud and facilitate subsequent operations using this range. </p><p>It should be noted that the Bounding Box in CloudComapre is <b>Axis-Aligned Bounding Box (AABB)</b>. In addition to AABB in CloudCompare, there is also a directed Bounding Box, which is called <b>Oriented Bounding Box (OBB)</b>. AABB and OBB are both Bounding Box. What is the difference between them?</p><ul><li><b>Oriented Bounding Box</b> is always aligned with the  principal component direction of the point cloud (PCA can be used to  calculate the principal component direction);</li><li><b>Axis-Aligned Bounding Box</b> is always aligned with the coordinate axis;</li></ul><p><img src="/2022/01/17/2-point-cloud/two_bounding_box.png" alt="Two different bounding boxes"></p><p>Through the above introduction, we can see that OBB is more accurate than AABB to describe the range of point cloud. AABB will frame much invalid space, which will have a particular impact on efficiency in actual algorithm application. When we need a piece of more accurate range information, we generally choose to calculate OBB.</p><h3 id="Cutting"><a href="#Cutting" class="headerlink" title="Cutting"></a>Cutting</h3><h4 id="ROI"><a href="#ROI" class="headerlink" title="ROI"></a>ROI</h4><p>Computer Vision is actually to let the computer automatically understand a picture or a scene. </p><p>Putting it in the background of the point cloud means that the computer can understand the point cloud like a human. For the point cloud of a car, people can immediately recognize that it is a car based on their knowledge, and can point out that it has wheels and so on. According to our needs, we can find out <b>the Region of Interest (ROI)</b>, that is, extract a specific point cloud region. ROI varies from situation to situation. It can be a wheel of a car point cloud, a spot on the hood of a car, or some unrelated points next to the vehicle.</p><h4 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h4><p>According to semantic segmentation, this idea is also used when we want to segment the point cloud into small individuals. Point cloud processing is essentially the same as the processing of 2D images. Many of the problems of 2D are the same as those of 3D, but the specific processing methods are different. 2D images also have semantic segmentation, aiming to understand the image and divide the image into semantic regions. Such as, given a photo, as shown below, the machine should be able to label cars, buildings, trees, and other objects in different colors after judging:</p><p><img src="/2022/01/17/2-point-cloud/2D_senmantic_seg.jpg" alt="2D semantic segmentation"></p><p>The point cloud is a crucial way of expressing 3-dimensional objects also to realize semantic segmentation. The figure below is a schematic diagram of the semantic segmentation of a 3D point cloud. The bridge body is divided into different parts (represented by different colors).</p><p><img src="/2022/01/17/2-point-cloud/pointcloud_semantic_seg.png" alt="Point cloud semantic segmentation"></p><p>How to use CloudCompare for point cloud cutting? You can find details in <a href="https://github.com/oxon-612/PointCloud_Tutorial/blob/main/Chapter2/Chapter2_en/Chapter2%20Point%20Cloud%20Software.md">PointCloud_Tutorial Chapter2</a></p><h3 id="Downsampling"><a href="#Downsampling" class="headerlink" title="Downsampling"></a>Downsampling</h3><p>Downsampling is a critical step in the process of the processing point cloud. Sometimes the point cloud file we get is huge. For example, a real bridge point cloud will have 2G to 3G. If we use this file to perform experiments or develop algorithms, it will significantly reduce efficiency. Therefore, we can choose to downsample to reduce the number of points in the point cloud and facilitate processing.</p><p>Downsampling is essentially a process from more to less, and the final point cloud is a subset of the original point cloud. The coordinates and colors of the points obtained by downsampling still correspond to their information in the original point cloud, as shown below:</p><p><img src="/2022/01/17/2-point-cloud/downsampling.png" alt="Downsampling"></p><p>CloudCompare provides three downsamping methods: <b>Random, Space, Octree</b></p><ul><li><p>Random</p><p><b>Advantage:</b> Random downsampling principle is simple. Just set the number of reserved points to select points as the left downsampling result point cloud randomly;</p><p><b>Disadvantage:</b> Random downsampling has no focus. Randomly select the entire point cloud so that important information may be lost.</p></li><li><p>Space</p><p>Space downsampling is based on distance.</p><p><b>Use active SF</b>:</p><p>Space also has an optional box Use active SF. SF is Scalar Field. There are many Scalar Fields in the point cloud, such as curvature, confidence, etc. We can set the space distance according to the value of these Scalar Fields instead of setting the same distance for the entire point cloud.</p><p>The most intuitive example is to set different distance thresholds according to different curvatures. Curvature, generally speaking, is the degree of bending. Some point cloud surface textures are involved, such as sculptures or other objects with uneven surfaces, and the curvature of these areas will be larger than other relatively flat surfaces. The area with large curvature means that it contains richer geometric information. The flat surfaces can be described by a few points or only three points (such as a plane). In contrast, the more complex and rugged surfaces need more points to describe their geometric properties. </p><p>In other words, the curvature can be used as an indicator to distinguish the geometric complexity of a surface. The smaller the curvature, the flatter the surface represented by the point cloud, and the lower the geometric complexity. On the contrary, the greater the curvature, the greater the degree of change of the surface represented by the point cloud, the more rugged, and the higher the geometric complexity. </p></li><li><p>Octree</p><p>Octree corresponds to ‚Äúbinary tree‚Äù:</p><p>Each node of the binary tree has up to 2 child nodes, and each node of the octree has up to 8 child nodes. The process of a continuous division of octree is essentially the process of constant equal division of small cubes, as shown in Fig.2.1.51. These small cubes are also called ‚Äúvoxels.‚Äù</p><p><img src="/2022/01/17/2-point-cloud/Octree.png" alt="Octree"></p><p>Processing steps:</p><p>step1: Use a small cube to frame the original point cloud;</p><p>step2: Set the Octree level. Here level = 1. This setup divides the big cube into eight small cubes. If there is no point in a small cube, the cube is deleted. </p><p>step3: core step of Octree. We keep the point which is the most close to the Central point of each voxel. And one voxel is allowed to keep only one point. </p><p><img src="/2022/01/17/2-point-cloud/octree_processing.png" alt="Octree processing"></p></li></ul><h3 id="Resampling"><a href="#Resampling" class="headerlink" title="Resampling"></a>Resampling</h3>]]></content>
    
    
    <categories>
      
      <category>Point Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Point Cloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1-Basic knowledge of point cloud</title>
    <link href="/2022/01/17/1-point-cloud-fundation/"/>
    <url>/2022/01/17/1-point-cloud-fundation/</url>
    
    <content type="html"><![CDATA[<h3 id="What-is-point-cloud"><a href="#What-is-point-cloud" class="headerlink" title="What is point cloud?"></a>What is point cloud?</h3><blockquote><p>Concept: </p><p>Point cloud is a massive collection of points expressing target spatial distribution and target surface characteristics in the same spatial coordinate system, which is the ‚ÄúSampling of object surface ‚Äú.</p></blockquote><ul><li><p><b>What does the same spatial coordinate system mean?  Why the same? </b></p><p>The same spatial coordinate system represents point cloud is the data in 3-dimensional space;</p><p>‚ÄúThe same‚Äù means that all points in the point cloud are in the same coordinate system, instead of belonging to multiple coordinate systems, as shown below:</p></li></ul><p><img src="/2022/01/17/1-point-cloud-fundation/The_same_coordinate_system.png" alt="The same coordinate system"></p><p>The concept of point cloud not only emphasizes that the point cloud is a ‚Äúcollection of points‚Äù, more importantly, the point cloud is a sampling of object surface ‚Äî‚Äî Sampling refers to the process of getting a sample of individuals from the population. Scanning is to sample the object surface, and the point cloud is sample points on the object surface.</p><h3 id="Point-Cloud-View"><a href="#Point-Cloud-View" class="headerlink" title="Point Cloud View"></a>Point Cloud View</h3><p>The following figure shows several point cloud views: rabbit.pcd, bridge.bin, chair.pcd, airplane.pcd, bottle.pcd.</p><p><img src="/2022/01/17/1-point-cloud-fundation/point_cloud_view.png" alt="Point cloud View"></p><h3 id="Features-of-point-cloud"><a href="#Features-of-point-cloud" class="headerlink" title="Features of point cloud"></a>Features of point cloud</h3><ul><li>Translation and rotation in space can not change characteristics of point cloud itself, which can be reflected in the point cloud algorithm many times. </li><li>What we focus on is the spatial coordinate or color and other information of each point. Thus, the point size and other irrelevant factors do not influence our research. It generally has an impact on the view.</li></ul><p><img src="/2022/01/17/1-point-cloud-fundation/point_size.png" alt="Point Size"></p><ul><li>The point cloud collection is non-intrusive. That is, there is no impact or interference on the scene or the building when we use a laser  scanner to scan them.</li></ul><h3 id="How-to-get-point-cloud"><a href="#How-to-get-point-cloud" class="headerlink" title="How to get point cloud?"></a>How to get point cloud?</h3><h4 id="Real-point-cloud"><a href="#Real-point-cloud" class="headerlink" title="Real point cloud"></a><b>Real point cloud</b></h4><p>The real point cloud is obtained from the objects in the real scene through some instruments. Such as 3D laser scanner.</p><h4 id="Virtual-point-cloud"><a href="#Virtual-point-cloud" class="headerlink" title="Virtual point cloud"></a><b>Virtual point cloud</b></h4><p>Open datasets:</p><p>There are also some public point cloud datasets available for download:</p><ul><li><p><i>The Stanford 3D Scanning Repository</i></p><p>linkÔºö <a href="http://www.cc.gatech.edu/projects/large_models/">http://www.cc.gatech.edu/projects/large_models/</a></p><p>When we are new to the point cloud, we can download many point cloud datasets from this website. Because the point cloud data volume of this website is small, the operation is convenient. Among them, ‚Äúbunny‚Äù (also known as Stanford Bunny) is often used in significant point cloud algorithm examples.</p><p><img src="/2022/01/17/1-point-cloud-fundation/stanford_3d.png" alt="The Stanford 3D Scanning Repository"></p></li><li><p><i>Sydney Urban Objects Dataset</i></p><p>linkÔºö<a href="http://www.acfr.usyd.edu.au/papers/SydneyUrbanObjectsDataset.shtml">http://www.acfr.usyd.edu.au/papers/SydneyUrbanObjectsDataset.shtml</a></p><p>This dataset was acquired using LiDAR in the CBD area of Sydney, Australia, and covers a variety of common urban road objects. Such as all kinds of vehicles on the road, pedestrians, roadside trees, etc., include a total of 631 individual scanned objects. They are mainly used to test matching and classification algorithms.</p><p><img src="/2022/01/17/1-point-cloud-fundation/arranged.png" alt="Sydney Urban Objects Dataset"></p></li><li><p><i>ASL Datasets Repository</i></p><p>linkÔºö<a href="https://projects.asl.ethz.ch/datasets/doku.php?id=home">https://projects.asl.ethz.ch/datasets/doku.php?id=home</a></p><p>This dataset contains many point cloud data, which can be used for target detection and matching, point cloud registration, etc.</p></li><li><p><i>The KITTI Vision Benchmark Suite</i></p><p>linkÔºö<a href="http://www.cvlibs.net/datasets/kitti/">http://www.cvlibs.net/datasets/kitti/</a></p><p>The KITTI Vision Benchmark Suite comes from a project of the Karlsruhe Institute of Technology in Germany. It contains a large number of urban environment point cloud datasets (KITTI) collected by KIT‚Äôs UGV platform. This dataset not only includes radar, image, GPS, and INS data but also has manually labeled segmentation and tracking results, which can be used to objectively evaluate the effect and performance of large-scale 3D modeling and classification</p><p><img src="/2022/01/17/1-point-cloud-fundation/KITTI.png" alt="The KITTI Vision Benchmark Suite"></p></li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol><li><a href="https://github.com/oxon-612/PointCloud_Tutorial">PointCloud_Tutorial</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Point Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Point Cloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>The first day at SleepTown</title>
    <link href="/2022/01/15/The-first-day-at-SleepTown/"/>
    <url>/2022/01/15/The-first-day-at-SleepTown/</url>
    
    <content type="html"><![CDATA[<p>Welcome to SleepTown! I‚Äôm the mayor, the first and maybe the only habitant of this town. </p><p>You guys can call me SleepyKIKI. And you must be curious about what life like in SleepTown. You can find answers below.</p><h2 id="Quick-Start-in-SleepTwon"><a href="#Quick-Start-in-SleepTwon" class="headerlink" title="Quick Start in SleepTwon"></a>Quick Start in SleepTwon</h2><h3 id="Why-to-create-this-Town-Blog"><a href="#Why-to-create-this-Town-Blog" class="headerlink" title="Why to create this Town(Blog)?"></a>Why to create this Town(Blog)?</h3><p>At first to record my college graduation project and some tech knowledge. But I also hope to record my sweet personal life. This is the space with happy moments and fragrant smell. </p><p>Hope you can enjoy the moments in SleepTown. If you feel tired, just get in and take a nap!</p><p><img src="/2022/01/15/The-first-day-at-SleepTown/Holiday_beach.png" alt="Holiday"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Daily life</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/01/14/hello-world/"/>
    <url>/2022/01/14/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></div></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo server<br></code></pre></div></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo generate<br></code></pre></div></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></div></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
